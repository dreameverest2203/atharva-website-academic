---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "MoCa: Cognitive Scaffolding for Language Models in Causal and Moral Judgment Tasks"
authors: ["Allen Nie, Atharva Amdekar, Christopher J. Piech, Tatsunori Hashimoto, Tobias Gerstenberg"]
# date: 2022-08-28T19:30:27-07:00
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: 2022-08-28T19:30:27-07:00

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: "Proceedings of the 39 th International Conference on Machine
Learning, Baltimore, Maryland, USA,"
publication_short: "ICML Workshop - Beyond Bayes Poster"

abstract: "Human common sense understanding of the physical and social world is organized around intuitive theories. Two key building blocks of these intuitive theories are causality and morality. Causal and moral judgments come naturally to people: who did what, and why? There is a rich literature in psychology and cognitive science that has studied people's causal and moral intuitions. This work has revealed a number of factors that systematically influence people's judgments, such as the presence of norms, and whether the agent was aware of their action's potential consequences. Here, we investigate whether large language models (LLMs) make causal and moral judgments about text-based scenarios that align with those of human participants. We find that without any annotations, LLMs and human participants are misaligned (only 56%-60% agreement). However, LLMs can accurately annotate what factors are present in a scenario with simple expert-written instructions. We show how these annotations can guide LLMs to match participants' judgments more closely (69.7%-72% agreement). These results suggest that insights from cognitive science can help scaffold language models to align more closely with human intuitions in a challenging common-sense evaluation task."

# Summary. An optional shortened abstract.
summary: "We introduce causal and moral judgment tasks and propose a cognitive science-informed multi-step reasoning strategy for large language models."

# tags: ["Natural Language Processing"]
categories: []
featured: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_pdf: https://drive.google.com/file/d/1PNCqgY7rzJjg22CsicQ0qwPtaTgjrhVV/view
url_code:
url_dataset:
url_poster:
url_project:
url_slides:
url_source:
url_video:

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---
